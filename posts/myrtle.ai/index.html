<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Myrtle.ai internship | Conor Williams</title><meta name=keywords content><meta name=description content="Internship at Myrtle.ai"><meta name=author content="Conor Williams"><link rel=canonical href=//conorwilliams.github.io/posts/myrtle.ai/><link crossorigin=anonymous href=/assets/css/stylesheet.deec51b4ebb14229cda677d98d194ddeeebc27943c57f551ca001ed945bcb9ec.css integrity="sha256-3uxRtOuxQinNpnfZjRlN3u68J5Q8V/VRygAe2UW8uew=" rel="preload stylesheet" as=style><link rel=icon href=//conorwilliams.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=//conorwilliams.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=//conorwilliams.github.io/favicon-32x32.png><link rel=apple-touch-icon href=//conorwilliams.github.io/apple-touch-icon.png><link rel=mask-icon href=//conorwilliams.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Myrtle.ai internship"><meta property="og:description" content="Internship at Myrtle.ai"><meta property="og:type" content="article"><meta property="og:url" content="//conorwilliams.github.io/posts/myrtle.ai/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-28T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-28T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Myrtle.ai internship"><meta name=twitter:description content="Internship at Myrtle.ai"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"//conorwilliams.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Myrtle.ai internship","item":"//conorwilliams.github.io/posts/myrtle.ai/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Myrtle.ai internship","name":"Myrtle.ai internship","description":"Internship at Myrtle.ai","keywords":[],"articleBody":"This year I had the fantastic opportunity to work with Myrtle.ai as one of their Machine Learning (ML) Interns. Myrtle.ai is a Cambridge based company that specializes in the development of low-latency ML models for accelerators.\nLong-term short-term RNNs My first project was to develop a custom LSTM module in CUDA to replace a pytorch implementation. This formed a key component of their FPGA automatic speech recognition pipeline. I delivered a solution that was 7.7x faster than their previous implementation and throughput competitive with NVIDIA’s hand-tuned CuDNN library.\nDuring this project I was re-exposed to the CUDA programming model and gained a deeper understanding of the CUDA memory hierarchy. I also gained experience with the profiling and debugging tools available in the CUDA ecosystem. Furthermore, I worked with pytorch and had the displeasure of working with the torch C++ API and extension system.\nMulti-blank and the transducer and loss After completing the LSTM module in three weeks earlier than expected, I was given the opportunity to work on a more inference focused project. I was tasked with implementing the state-of-the-art Multi-blank extension to the transducer loss function. This is a novel extension to the transducer loss function that allows for the use of multiple blank tokens in the output sequence. Using my implementation I trained a model with identical word-error rates to the previous best, with the potential to halve inference-time latency.\nMemory bottlenecks During my time working on the transducer loss function (which is the memory bottleneck of most ASR models) I identified several stages in the training pipeline that could be optimized. I implemented a specialized map-reduce algorithm (re-igniting my interest in warp level programming) and by fusing several steps before/after the loss function. Ultimately, I increased the training batch size by 85% which reduced training times/costs by a similar fraction.\nSummary In my penultimate week I presented my work to the company and received very positive feedback. The code I wrote has been deployed at Myrtle and is currently being used to train models for their clients.\nI am very grateful to Myrtle for the opportunity to work with them and their stellar team.\n","wordCount":"357","inLanguage":"en","datePublished":"2023-08-28T00:00:00Z","dateModified":"2023-08-28T00:00:00Z","author":{"@type":"Person","name":"Conor Williams"},"mainEntityOfPage":{"@type":"WebPage","@id":"//conorwilliams.github.io/posts/myrtle.ai/"},"publisher":{"@type":"Organization","name":"Conor Williams","logo":{"@type":"ImageObject","url":"//conorwilliams.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//conorwilliams.github.io accesskey=h title="Conor Williams (Alt + H)">Conor Williams</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=//conorwilliams.github.io/aboutme/ title=About><span>About</span></a></li><li><a href=//conorwilliams.github.io/archives/ title=Blog><span>Blog</span></a></li><li><a href=//conorwilliams.github.io/publications/ title=Publications><span>Publications</span></a></li><li><a href=//conorwilliams.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Myrtle.ai internship</h1><div class=post-description>Internship at Myrtle.ai</div><div class=post-meta><span title='2023-08-28 00:00:00 +0000 UTC'>August 28, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Conor Williams&nbsp;|&nbsp;<a href=https://github.com/conorwilliams/ConorWilliams.github.io/blob/main/content/posts/myrtle.ai/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>This year I had the fantastic opportunity to work with <a href=https://myrtle.ai/>Myrtle.ai</a> as one of their Machine Learning (ML) Interns. Myrtle.ai is a Cambridge based company that specializes in the development of low-latency ML models for accelerators.</p><h2 id=long-term-short-term-rnns>Long-term short-term RNNs<a hidden class=anchor aria-hidden=true href=#long-term-short-term-rnns>#</a></h2><p>My first project was to develop a custom LSTM module in CUDA to replace a pytorch implementation. This formed a key component of their FPGA automatic speech recognition pipeline. I delivered a solution that was 7.7x faster than their previous implementation and throughput competitive with NVIDIA&rsquo;s hand-tuned CuDNN library.</p><p>During this project I was re-exposed to the CUDA programming model and gained a deeper understanding of the CUDA memory hierarchy. I also gained experience with the profiling and debugging tools available in the CUDA ecosystem. Furthermore, I worked with pytorch and had the <del>dis</del>pleasure of working with the torch C++ API and extension system.</p><h2 id=multi-blank-and-the-transducer-and-loss>Multi-blank and the transducer and loss<a hidden class=anchor aria-hidden=true href=#multi-blank-and-the-transducer-and-loss>#</a></h2><p>After completing the LSTM module in three weeks earlier than expected, I was given the opportunity to work on a more inference focused project. I was tasked with implementing the state-of-the-art <a href=https://arxiv.org/abs/2211.03541>Multi-blank extension</a> to the transducer loss function. This is a novel extension to the transducer loss function that allows for the use of multiple blank tokens in the output sequence. Using my implementation I trained a model with identical word-error rates to the previous best, with the potential to halve inference-time latency.</p><h3 id=memory-bottlenecks>Memory bottlenecks<a hidden class=anchor aria-hidden=true href=#memory-bottlenecks>#</a></h3><p>During my time working on the transducer loss function (which is the memory bottleneck of most ASR models) I identified several stages in the training pipeline that could be optimized. I implemented a specialized map-reduce algorithm (re-igniting my interest in warp level programming) and by fusing several steps before/after the loss function. Ultimately, I increased the training batch size by 85% which reduced training times/costs by a similar fraction.</p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>In my penultimate week I <a href=main.pdf>presented my work</a> to the company and received very positive feedback. The code I wrote has been deployed at Myrtle and is currently being used to train models for their clients.</p><p>I am very grateful to Myrtle for the opportunity to work with them and their stellar team.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=//conorwilliams.github.io/posts/tms2023/><span class=title>Next »</span><br><span>TMS2023</span></a></nav></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>